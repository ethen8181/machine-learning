{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "145b9947-8967-4bc2-bb43-a15a48f815aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    html {\n",
       "        font-size: 18px !important;\n",
       "    }\n",
       "\n",
       "    body {\n",
       "        background-color: #FFF !important;\n",
       "        font-weight: 1rem;\n",
       "        font-family: 'Source Sans Pro', \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n",
       "    }\n",
       "\n",
       "    body .notebook-app {\n",
       "        background-color: #FFF !important;\n",
       "    }\n",
       "\n",
       "    #header {\n",
       "        box-shadow: none !important;\n",
       "    }\n",
       "\n",
       "    #notebook {\n",
       "        padding-top: 0px;\n",
       "    }\n",
       "\n",
       "    #notebook-container {\n",
       "        box-shadow: none;\n",
       "        -webkit-box-shadow: none;\n",
       "        padding: 10px;\n",
       "    }\n",
       "\n",
       "    div.cell {\n",
       "        width: 1000px;\n",
       "        margin-left: 0% !important;\n",
       "        margin-right: auto;\n",
       "    }\n",
       "\n",
       "    div.cell.selected {\n",
       "        border: 1px dashed #CCCCCC;\n",
       "    }\n",
       "\n",
       "    .edit_mode div.cell.selected {\n",
       "        border: 1px dashed #828282;\n",
       "    }\n",
       "\n",
       "    div.output_wrapper {\n",
       "        margin-top: 8px;\n",
       "    }\n",
       "\n",
       "    a {\n",
       "        color: #383838;\n",
       "    }\n",
       "\n",
       "    code,\n",
       "    kbd,\n",
       "    pre,\n",
       "    samp {\n",
       "        font-family: 'Menlo', monospace !important;\n",
       "        font-size: 0.75rem !important;\n",
       "    }\n",
       "\n",
       "    h1 {\n",
       "        font-size: 2rem !important;\n",
       "        font-weight: 500 !important;\n",
       "        letter-spacing: 3px !important;\n",
       "        text-transform: uppercase !important;\n",
       "    }\n",
       "\n",
       "    h2 {\n",
       "        font-size: 1.8rem !important;\n",
       "        font-weight: 400 !important;\n",
       "        letter-spacing: 3px !important;\n",
       "        text-transform: none !important;\n",
       "    }\n",
       "\n",
       "    h3 {\n",
       "        font-size: 1.5rem !important;\n",
       "        font-weight: 400 !important;\n",
       "        font-style: italic !important;\n",
       "        display: block !important;\n",
       "    }\n",
       "\n",
       "    h4,\n",
       "    h5,\n",
       "    h6 {\n",
       "        font-size: 1rem !important;\n",
       "        font-weight: 400 !important;\n",
       "        display: block !important;\n",
       "    }\n",
       "\n",
       "    .prompt {\n",
       "        font-family: 'Menlo', monospace !important;\n",
       "        font-size: 0.75rem;\n",
       "        text-align: right;\n",
       "        line-height: 1.21429rem;\n",
       "    }\n",
       "\n",
       "    /* INTRO PAGE */\n",
       "\n",
       "    .toolbar_info,\n",
       "    .list-container {\n",
       "        ;\n",
       "    }\n",
       "    /* NOTEBOOK */\n",
       "\n",
       "    div#header-container {\n",
       "        display: none !important;\n",
       "    }\n",
       "\n",
       "    div#notebook {\n",
       "        border-top: none;\n",
       "        font-size: 1rem;\n",
       "    }\n",
       "\n",
       "    div.input_prompt {\n",
       "        color: #C74483;\n",
       "    }\n",
       "\n",
       "    .code_cell div.input_prompt:after,\n",
       "    div.output_prompt:after {\n",
       "        content: '\\25b6';\n",
       "    }\n",
       "\n",
       "    div.output_prompt {\n",
       "        color: #2B88D9;\n",
       "    }\n",
       "\n",
       "    div.input_area {\n",
       "        border-radius: 0px;\n",
       "        border: 1px solid #d8d8d8;\n",
       "    }\n",
       "\n",
       "    div.output_area pre {\n",
       "        font-weight: normal;\n",
       "    }\n",
       "\n",
       "    div.output_subarea {\n",
       "        font-weight: normal;\n",
       "    }\n",
       "\n",
       "    .rendered_html pre,\n",
       "    .rendered_html table,\n",
       "    .rendered_html th,\n",
       "    .rendered_html tr,\n",
       "    .rendered_html td {\n",
       "        border: 1px #828282 solid;\n",
       "        font-size: 0.75rem;\n",
       "        font-family: 'Menlo', monospace;\n",
       "    }\n",
       "\n",
       "    .rendered_html th,\n",
       "    .rendered_html tr,\n",
       "    .rendered_html td {\n",
       "        padding: 5px 10px;\n",
       "    }\n",
       "\n",
       "    .rendered_html th {\n",
       "        font-weight: normal;\n",
       "        background: #f8f8f8;\n",
       "    }\n",
       "\n",
       "    a:link{\n",
       "       font-weight: bold;\n",
       "       color:#447adb;\n",
       "    }\n",
       "    a:visited{\n",
       "       font-weight: bold;\n",
       "       color: #1d3b84;\n",
       "    }\n",
       "    a:hover{\n",
       "       font-weight: bold;\n",
       "       color: #1d3b84;\n",
       "    }\n",
       "    a:focus{\n",
       "       font-weight: bold;\n",
       "       color:#447adb;\n",
       "    }\n",
       "    a:active{\n",
       "       font-weight: bold;\n",
       "       color:#447adb;\n",
       "    }\n",
       "    .rendered_html :link {\n",
       "       text-decoration: underline; \n",
       "    }\n",
       "\n",
       "    div.output_html {\n",
       "        font-weight: 1rem;\n",
       "        font-family: 'Source Sans Pro', \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n",
       "    }\n",
       "\n",
       "    table.dataframe tr {\n",
       "        border: 1px #CCCCCC;\n",
       "    }\n",
       "\n",
       "    div.cell.selected {\n",
       "        border-radius: 0px;\n",
       "    }\n",
       "\n",
       "    div.cell.edit_mode {\n",
       "        border-radius: 0px;\n",
       "        border: thin solid #CF5804;\n",
       "    }\n",
       "\n",
       "    span.ansiblue {\n",
       "        color: #00A397;\n",
       "    }\n",
       "\n",
       "    span.ansigray {\n",
       "        color: #d8d8d8;\n",
       "    }\n",
       "\n",
       "    span.ansigreen {\n",
       "        color: #688A0A;\n",
       "    }\n",
       "\n",
       "    span.ansipurple {\n",
       "        color: #975DDE;\n",
       "    }\n",
       "\n",
       "    span.ansired {\n",
       "        color: #D43132;\n",
       "    }\n",
       "\n",
       "    span.ansiyellow {\n",
       "        color: #D9AA00;\n",
       "    }\n",
       "\n",
       "    div.output_stderr {\n",
       "        background-color: #D43132;\n",
       "    }\n",
       "\n",
       "    div.output_stderr pre {\n",
       "        color: #e8e8e8;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython.CodeMirror {\n",
       "        background: #F8F8F8;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython div.CodeMirror-selected {\n",
       "        background: #e8e8e8 !important;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython .CodeMirror-gutters {\n",
       "        background: #F8F8F8;\n",
       "        border-right: 0px;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython .CodeMirror-linenumber {\n",
       "        color: #b8b8b8;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython .CodeMirror-cursor {\n",
       "        border-left: 1px solid #585858 !important;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-atom {\n",
       "        color: #C74483;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-number {\n",
       "        color: #C74483;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-property,\n",
       "    .cm-s-ipython span.cm-attribute {\n",
       "        color: #688A0A;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-keyword {\n",
       "        font-weight: normal;\n",
       "        color: #D43132;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-string {\n",
       "        color: #D9AA00;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-operator {\n",
       "        font-weight: normal;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-builtin {\n",
       "        color: #2B88D9;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-variable {\n",
       "        color: #00A397;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-variable-2 {\n",
       "        color: #2B88D9;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-def {\n",
       "        color: #00A397;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-error {\n",
       "        background: #FFBDBD;\n",
       "        color: #D43132;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-tag {\n",
       "        color: #D43132;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-link {\n",
       "        color: #975DDE;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython .CodeMirror-matchingbracket {\n",
       "        text-decoration: underline;\n",
       "         !important;\n",
       "    }\n",
       "</style>\n",
       "\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"]\n",
       "                           },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    scale:100,\n",
       "                        availableFonts: [],\n",
       "                        preferredFont:null,\n",
       "                        webFont: \"TeX\",\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code for loading the format for the notebook\n",
    "import os\n",
    "\n",
    "# path : store the current path to convert back to it later\n",
    "path = os.getcwd()\n",
    "os.chdir(os.path.join('..', '..', 'notebook_format'))\n",
    "\n",
    "from formats import load_style\n",
    "load_style(css_style='custom2.css', plot_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c927d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Ethen\n",
      "\n",
      "Last updated: 2023-04-15\n",
      "\n",
      "datasets    : 2.11.0\n",
      "pandas      : 1.4.3\n",
      "scipy       : 1.9.0\n",
      "numpy       : 1.23.2\n",
      "torch       : 2.0.0\n",
      "transformers: 4.28.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "os.chdir(path)\n",
    "\n",
    "# 1. magic for inline plot\n",
    "# 2. magic to print version\n",
    "# 3. magic so that the notebook will reload external python modules\n",
    "# 4. magic to enable retina (high resolution) plots\n",
    "# https://gist.github.com/minrk/3301035\n",
    "%matplotlib inline\n",
    "%load_ext watermark\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import scipy\n",
    "import datasets\n",
    "import transformers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from time import perf_counter\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import (\n",
    "    load_dataset,\n",
    "    concatenate_datasets,\n",
    "    disable_progress_bar,\n",
    "    DatasetDict\n",
    ")\n",
    "from datasets.utils.logging import set_verbosity_error\n",
    "from transformers import (\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    AutoModel,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    EarlyStoppingCallback,\n",
    "    IntervalStrategy\n",
    ")\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.metrics.pairwise import paired_cosine_distances\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "cache_dir = None\n",
    "\n",
    "%watermark -a 'Ethen' -d -u -iv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e59ab0d",
   "metadata": {},
   "source": [
    "# Sentence Transformer: Training Bi-Encoder via Contrastive Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e74fd1f",
   "metadata": {},
   "source": [
    "In modern recommendation system, it is common to have two major distinct stages, a recall/retrieval stage, and a ranking stage [[2]](https://fennel.ai/blog/real-world-recommendation-system/) [[3]](https://www.sbert.net/examples/applications/retrieve_rerank/README.html). In this article, we'll be discussing these two stages in the context of a pre-trained encoder model, where different types of architectures are commonly used at different stages to reflect their own strength.\n",
    "\n",
    "<img src=\"imgs/stages.png\">\n",
    "\n",
    "Recall/Retrieval focuses on candidate generation, given we have a million things be it inventories, passages, etc. stored in our database, we need a way to efficiently retrieve a subset of them that are more relevant for the given context. In encoder model's paradigm, this means we need a way to represent our incoming context be it query, questions, etc. in a vector representation, often times referred to as sentence embedding and perform a similarity search between that with entities that are also already represented in a sentence embedding. This step is often done using the bi-encoder architecture, where we can pass individual sentences/entities through our encoder and then perform similarity search using metrics such as cosine similarity. Being able to input individual entities through our encoder is the key to an effient retrieval stage, where we need to quickly scan through our database, as it means we can often times pre-compute these results apriori.\n",
    "\n",
    "<img src=\"imgs/bi_encoder.png\">\n",
    "\n",
    "These subsets are then passed to the ranker, where given we now have our pairs, we need to score these pairs so the system can assign a score to rank these retrieved inventories in a sorted order. This step is often done using cross encoder, a.k.a. cross attention architectures. Cross encoder doesn't produce sentence embeddings for our data but instead relies on classification mechansim for out input pairs, hence whenever we have a fixed set of data pairs we wish to score, cross encoder often times achieves better performance than their bi encoder counterparts even when using less training data.\n",
    "\n",
    "<img src=\"imgs/cross_encoder.png\">\n",
    "\n",
    "In this document, our focus will be how to train bi-encoder style architecture using contrastive loss [[1]](https://www.pinecone.io/learn/fine-tune-sentence-transformers-mnr/) [[4]](https://github.com/UKPLab/sentence-transformers/tree/master/examples/training/nli)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f64d12",
   "metadata": {},
   "source": [
    "## Contrastive Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f566b16",
   "metadata": {},
   "source": [
    "For Bi-encoder, our input data at the bare minimum needs to contain positive pairs, where we need to be creative and define what's the definition for positive pairs based on our use case. These pairs are often referred to as anchors $a$ and positives, $p$. Given our dataset, the standard architecture for these type of task is a siamese network. Each base arm involves using a pre-trained encoder followed by a pooling operator for deriving a fix sized sentence embedding vector. During each step we feed both our anchor and positive one at time through the same encoder plus pooling arm. This encoder plus pooling arm's weights are often tied for our pairs. Tying weights ensure similar entities are mapped to similar locations in the representation space.\n",
    "\n",
    "For training this network, what we wish to accomplish is have our anchor and positive pairs $a_i$ and $p_i$ become closer in the vector space, whereas $a_i$ and some random negative examples $p_j$ becomes distant in vector space.\n",
    "\n",
    "\\begin{align}\n",
    "L = -\\frac{1}{n} \\sum^n_{i=1} \\frac{exp(sim(a_i, p_i))}{\\sum_j exp(sim(a_i, p_j))}\n",
    "\\end{align}\n",
    "\n",
    "Where $sim$ is a similarity function such as cosine similarity or dot product. This can then be treated as a classification task using cross entropy loss. $p_j$ is often times sampled using in batch negatives, meaning for each example in a batch, other examples' positives will be taken as its negatives, this effectively re-uses the already sampled data in our current batch without the need to implement additional negative sampling logic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791059ea",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4245548",
   "metadata": {},
   "source": [
    "For our dataset, we'll be using [Stanford Natural Language Inference (SNLI)](https://nlp.stanford.edu/projects/snli/) and [Multi-Genre NLI (MNLI)](https://cims.nyu.edu/~sbowman/multinli/), refer to its link for more details on these two datasets. For constrastive loss, we will filter out premise and hypothesis pairs that has a label 0 assigned to it. These are positive samples where the premise suggests the hypothesis.\n",
    "\n",
    "We'll also use the [Semantic Textual Similarity Benchmark (stsb)](https://arxiv.org/abs/1708.00055) dataset each contains sentence pairs with human annotated similarity score from 1 to 5 for evaluating our model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5bba4c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['anchor_text', 'positive_text', 'label'],\n",
       "        num_rows: 5749\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['anchor_text', 'positive_text', 'label'],\n",
       "        num_rows: 1500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['anchor_text', 'positive_text', 'label'],\n",
       "        num_rows: 1379\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prevents progress bar and logging from flooding our document\n",
    "disable_progress_bar()\n",
    "set_verbosity_error()\n",
    "\n",
    "stsb = load_dataset('glue', 'stsb', cache_dir=cache_dir)\n",
    "\n",
    "# we normalize the score to a range of 0 ~ 1\n",
    "stsb = stsb.map(lambda x: {'label': x['label'] / 5.0})\n",
    "stsb = stsb.rename_column(\"sentence1\", \"anchor_text\")\n",
    "stsb = stsb.rename_column(\"sentence2\", \"positive_text\")\n",
    "stsb = stsb.remove_columns([\"idx\"])\n",
    "stsb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e80c1f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anchor_text': 'A young child is riding a horse.',\n",
       " 'positive_text': 'A child is riding a horse.',\n",
       " 'label': 0.949999988079071}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stsb[\"validation\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87ae8e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['anchor_text', 'positive_text', 'label'],\n",
       "        num_rows: 314315\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['anchor_text', 'positive_text', 'label'],\n",
       "        num_rows: 5749\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['anchor_text', 'positive_text', 'label'],\n",
       "        num_rows: 1500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snli = load_dataset('snli', cache_dir=cache_dir)\n",
    "mnli = load_dataset('glue', 'mnli', cache_dir=cache_dir)\n",
    "mnli = mnli.remove_columns(['idx'])\n",
    "snli = snli.cast(mnli[\"train\"].features)\n",
    "\n",
    "dataset_train = concatenate_datasets([snli[\"train\"], mnli[\"train\"]])\n",
    "dataset_train = dataset_train.filter(lambda x: x['label'] == 0)\n",
    "dataset_train = dataset_train.rename_column(\"premise\", \"anchor_text\")\n",
    "dataset_train = dataset_train.rename_column(\"hypothesis\", \"positive_text\")\n",
    "\n",
    "# note that we are evaluating the performance of our sentence embedding on\n",
    "# stsb dataset without using any stsb samples in our training dataset\n",
    "dataset_dict = DatasetDict({\n",
    "    \"train\": dataset_train,\n",
    "    \"validation\": stsb[\"train\"],\n",
    "    \"test\": stsb[\"validation\"]\n",
    "})\n",
    "dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2180f72f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anchor_text': 'A person on a horse jumps over a broken down airplane.',\n",
       " 'positive_text': 'A person is outdoors, on a horse.',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2082ef6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# we can experiment with different pre-trained model checkpoint, e.g. \"roberta-base\"\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=cache_dir)\n",
    "model = AutoModel.from_pretrained(model_name, cache_dir=cache_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8b0949",
   "metadata": {},
   "source": [
    "As usual, we tokenize our anchor and positive text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4a90c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_fn(examples):\n",
    "    tokenized = tokenizer(examples[\"anchor_text\"], truncation=True, max_length=128)\n",
    "    examples[\"anchor_input_ids\"] = tokenized[\"input_ids\"]\n",
    "    examples[\"anchor_attention_mask\"] = tokenized[\"attention_mask\"]\n",
    "\n",
    "    tokenized = tokenizer(examples[\"positive_text\"], truncation=True, max_length=128)\n",
    "    examples[\"positive_input_ids\"] = tokenized[\"input_ids\"]\n",
    "    examples[\"positive_attention_mask\"] = tokenized[\"attention_mask\"]\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0121d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'anchor_input_ids', 'anchor_attention_mask', 'positive_input_ids', 'positive_attention_mask'],\n",
       "        num_rows: 314315\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['label', 'anchor_input_ids', 'anchor_attention_mask', 'positive_input_ids', 'positive_attention_mask'],\n",
       "        num_rows: 5749\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'anchor_input_ids', 'anchor_attention_mask', 'positive_input_ids', 'positive_attention_mask'],\n",
       "        num_rows: 1500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict_tokenized = dataset_dict.map(\n",
    "    tokenize_fn,\n",
    "    batched=True,\n",
    "    num_proc=8,\n",
    "    remove_columns=[\"anchor_text\", \"positive_text\"]\n",
    ")\n",
    "dataset_dict_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65cfb715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 0,\n",
       " 'anchor_input_ids': [101,\n",
       "  1037,\n",
       "  2711,\n",
       "  2006,\n",
       "  1037,\n",
       "  3586,\n",
       "  14523,\n",
       "  2058,\n",
       "  1037,\n",
       "  3714,\n",
       "  2091,\n",
       "  13297,\n",
       "  1012,\n",
       "  102],\n",
       " 'anchor_attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 'positive_input_ids': [101,\n",
       "  1037,\n",
       "  2711,\n",
       "  2003,\n",
       "  19350,\n",
       "  1010,\n",
       "  2006,\n",
       "  1037,\n",
       "  3586,\n",
       "  1012,\n",
       "  102],\n",
       " 'positive_attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict_tokenized[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc8dbd5",
   "metadata": {},
   "source": [
    "Here we also define a customize collate function for batching our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85305c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Optional, Union\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase\n",
    "from transformers.file_utils import PaddingStrategy\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForSiamese:\n",
    "    \"\"\"\n",
    "    Huggingface's DataCollatorWithPadding is for a single input, here we extend it\n",
    "    to take paired inputs.\n",
    "    \n",
    "    References\n",
    "    ----------\n",
    "    https://huggingface.co/docs/transformers/main_classes/data_collator#transformers.DataCollatorWithPadding\n",
    "    \"\"\"\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "    return_tensors: str = \"pt\"\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, List[int]]]) -> Dict[str, torch.Tensor]:\n",
    "        anchor_features = {\n",
    "            \"input_ids\": [feature[\"anchor_input_ids\"] for feature in features],\n",
    "            \"attention_mask\": [feature[\"anchor_attention_mask\"] for feature in features],\n",
    "            \"label\": [feature[\"label\"] for feature in features]\n",
    "        }\n",
    "        pos_features = {\n",
    "            \"input_ids\": [feature[\"positive_input_ids\"] for feature in features],\n",
    "            \"attention_mask\": [feature[\"positive_attention_mask\"] for feature in features]\n",
    "        }\n",
    "        anchor_batch = self.tokenizer.pad(\n",
    "            anchor_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=self.return_tensors,\n",
    "        )\n",
    "        pos_batch = self.tokenizer.pad(\n",
    "            pos_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=self.return_tensors,\n",
    "        )\n",
    "\n",
    "        batch = {\n",
    "            \"anchor_input_ids\": anchor_batch[\"input_ids\"],\n",
    "            \"anchor_attention_mask\": anchor_batch[\"attention_mask\"],\n",
    "            \"positive_input_ids\": pos_batch[\"input_ids\"],\n",
    "            \"positive_attention_mask\": pos_batch[\"attention_mask\"],\n",
    "            \"labels\": anchor_batch[\"label\"]\n",
    "        }\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd3a3237",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'anchor_input_ids': tensor([[  101,  1037,  2711,  2006,  1037,  3586, 14523,  2058,  1037,  3714,\n",
       "           2091, 13297,  1012,   102],\n",
       "         [  101,  2336,  5629,  1998, 12015,  2012,  4950,   102,     0,     0,\n",
       "              0,     0,     0,     0]]),\n",
       " 'anchor_attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]]),\n",
       " 'positive_input_ids': tensor([[  101,  1037,  2711,  2003, 19350,  1010,  2006,  1037,  3586,  1012,\n",
       "            102],\n",
       "         [  101,  2045,  2024,  2336,  2556,   102,     0,     0,     0,     0,\n",
       "              0]]),\n",
       " 'positive_attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]]),\n",
       " 'labels': tensor([0, 0])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample output from a data loader\n",
    "batch_size = 2\n",
    "data_collator = DataCollatorForSiamese(tokenizer)\n",
    "data_loader = DataLoader(dataset_dict_tokenized[\"train\"], batch_size=batch_size, collate_fn=data_collator)\n",
    "batch = next(iter(data_loader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e17197",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccda145",
   "metadata": {},
   "source": [
    "This section defines our transformer followed by pooling encoder, siamese network, evaluation metric, then proceed with using transformer library's Trainer class for training our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec1c9052",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerPoolingEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self, model_name: str, pooling_mode: str = \"avg\", cache_dir = None):\n",
    "        super().__init__()\n",
    "        if pooling_mode not in {\"avg\", \"cls\"}:\n",
    "            raise ValueError(f\"{pooling_mode} needs to one of avg, cls\")\n",
    "\n",
    "        self.base_model = AutoModel.from_pretrained(model_name, cache_dir=cache_dir)\n",
    "        self.pooling_mode = pooling_mode\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output = self.base_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        if self.pooling_mode == \"avg\":\n",
    "            # reshape attention mask to cover all hidden dimension\n",
    "            mask = attention_mask.unsqueeze(dim=-1).expand_as(output.last_hidden_state)\n",
    "            # perform mean pooling, but excluding attention mask\n",
    "            pooled = torch.sum(output.last_hidden_state * mask, dim=1) / torch.clamp(\n",
    "                mask.sum(dim=1), min=1e-9\n",
    "            )\n",
    "        elif self.pooling_mode == \"cls\":\n",
    "            pooled = output.last_hidden_state[:, 0, :]\n",
    "\n",
    "        return pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a798b379",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseModel(nn.Module):\n",
    "    \"\"\"\n",
    "    The loss function we are using is similar to Multiple Negative Ranking Loss that's mentioned\n",
    "    in the sentence bert package.\n",
    "    \n",
    "    The similarity function implemented here is cosine similarity, with cosine similarity, we often\n",
    "    times add a scaling multiplier. As cosine similarity's range is between -1 and 1, this scaling\n",
    "    factor ensures our loss are large enough between positive and negative samples for the network\n",
    "    to train.\n",
    "    \n",
    "    References\n",
    "    ----------\n",
    "    https://www.sbert.net/docs/package_reference/losses.html#multiplenegativesrankingloss\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str, scale: float = 20.0, pooling_mode: str = \"avg\", cache_dir = None):\n",
    "        super().__init__()\n",
    "        self.encoder = TransformerPoolingEncoder(model_name, pooling_mode, cache_dir)\n",
    "        self.scale = scale\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        anchor_input_ids,\n",
    "        anchor_attention_mask,\n",
    "        positive_input_ids,\n",
    "        positive_attention_mask,\n",
    "        labels=None\n",
    "    ):\n",
    "        # [batch size, hidden dim]\n",
    "        anchor_embedding = self.encoder(\n",
    "            input_ids=anchor_input_ids,\n",
    "            attention_mask=anchor_attention_mask\n",
    "        )\n",
    "        positive_embedding = self.encoder(\n",
    "            input_ids=positive_input_ids,\n",
    "            attention_mask=positive_attention_mask\n",
    "        )\n",
    "\n",
    "        # cosine similarity\n",
    "        anchor_norm = F.normalize(anchor_embedding, p=2, dim=1)\n",
    "        positive_norm = F.normalize(positive_embedding, p=2, dim=1)\n",
    "        scores = torch.mm(anchor_norm, positive_norm.transpose(0, 1)) * self.scale\n",
    "\n",
    "        # Example a[i] should match with p[i]\n",
    "        labels = torch.arange(scores.size()[0], device=scores.device)\n",
    "        loss = F.cross_entropy(scores, labels)\n",
    "        return loss, anchor_embedding, positive_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99559bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = SiameseModel(model_name, cache_dir=cache_dir).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee6e2b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.4709, device='cuda:0'),\n",
       " tensor([[-0.1386, -0.0835, -0.2738,  ..., -0.3862,  0.0325, -0.0017],\n",
       "         [ 0.3649,  0.3073,  0.0864,  ..., -0.2507,  0.2876, -0.0527]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0968, -0.2067, -0.0868,  ..., -0.4490, -0.0050,  0.0568],\n",
       "         [-0.0548,  0.0111,  0.1266,  ..., -0.1976,  0.2901, -0.1404]],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample forward output from the model given our input batch\n",
    "for key, tensor in batch.items():\n",
    "    batch[key] = tensor.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(**batch)\n",
    "    \n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2863c4",
   "metadata": {},
   "source": [
    "For our evaluation metric, we will first compute the cosine similarity of our pairs' embedding, then calculate pearson and spearman correlation with our ground truth similarity score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "114fccb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_prediction):\n",
    "    anchor_embedding, positive_embedding = eval_prediction.predictions\n",
    "    labels = eval_prediction.label_ids\n",
    "\n",
    "    cosine_sim = 1 - paired_cosine_distances(anchor_embedding, positive_embedding)\n",
    "    pearson, _ = pearsonr(labels, cosine_sim)\n",
    "    spearman, _ = spearmanr(labels, cosine_sim)\n",
    "    return {\"pearson\": round(pearson, 3), \"spearman\": round(spearman, 3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "feebfdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['DISABLE_MLFLOW_INTEGRATION'] = 'TRUE'\n",
    "\n",
    "finetuned_checkpoint = f\"{model_name}-siamese\"\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=finetuned_checkpoint,\n",
    "    num_train_epochs=2,\n",
    "    learning_rate=0.0001,\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=256,\n",
    "    weight_decay=0.01,\n",
    "    fp16=True,\n",
    "    evaluation_strategy=IntervalStrategy.STEPS,\n",
    "    save_strategy=IntervalStrategy.STEPS,\n",
    "    eval_steps=500,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"spearman\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args=training_args, \n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset_dict_tokenized['train'],\n",
    "    eval_dataset=dataset_dict_tokenized['validation'],\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e77b5628",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6500' max='9824' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6500/9824 08:57 < 04:35, 12.08 it/s, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Spearman</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.300400</td>\n",
       "      <td>2.122955</td>\n",
       "      <td>0.782000</td>\n",
       "      <td>0.755000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.234200</td>\n",
       "      <td>2.186666</td>\n",
       "      <td>0.789000</td>\n",
       "      <td>0.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.216200</td>\n",
       "      <td>2.237437</td>\n",
       "      <td>0.791000</td>\n",
       "      <td>0.762000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.202000</td>\n",
       "      <td>2.220945</td>\n",
       "      <td>0.803000</td>\n",
       "      <td>0.776000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.184900</td>\n",
       "      <td>2.192533</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.772000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.182200</td>\n",
       "      <td>2.195967</td>\n",
       "      <td>0.802000</td>\n",
       "      <td>0.774000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.172800</td>\n",
       "      <td>2.239089</td>\n",
       "      <td>0.807000</td>\n",
       "      <td>0.779000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.161300</td>\n",
       "      <td>2.302346</td>\n",
       "      <td>0.801000</td>\n",
       "      <td>0.773000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.161600</td>\n",
       "      <td>2.299685</td>\n",
       "      <td>0.799000</td>\n",
       "      <td>0.773000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.145900</td>\n",
       "      <td>2.234666</td>\n",
       "      <td>0.806000</td>\n",
       "      <td>0.781000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.105800</td>\n",
       "      <td>2.264370</td>\n",
       "      <td>0.807000</td>\n",
       "      <td>0.781000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.112700</td>\n",
       "      <td>2.267491</td>\n",
       "      <td>0.806000</td>\n",
       "      <td>0.777000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.104400</td>\n",
       "      <td>2.288190</td>\n",
       "      <td>0.808000</td>\n",
       "      <td>0.781000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87dfc953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.7663321495056152,\n",
       " 'eval_pearson': 0.839,\n",
       " 'eval_spearman': 0.838,\n",
       " 'eval_runtime': 0.3629,\n",
       " 'eval_samples_per_second': 4133.329,\n",
       " 'eval_steps_per_second': 16.533,\n",
       " 'epoch': 1.32}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(dataset_dict_tokenized[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1517cf",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2df10b",
   "metadata": {},
   "source": [
    "Quantitative benchmark on our test set shows we are capable of achieving a 80+% spearman correlation. This section performs a manual inspection on some sample input sentences, where some are more similar compared to others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebc86621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2009,  3236,  2032,  2125,  3457,  2008,  2686,  9557,  1997,\n",
       "          2712,  5596, 21475,   102,     0,     0,     0,     0,     0],\n",
       "        [  101,  2016,  2071,  2025,  5630,  2090,  4169,  2014,  4091,  2030,\n",
       "         12766,  2014, 10063,   102,     0,     0,     0,     0,     0],\n",
       "        [  101,  2002,  2245,  2045,  1005,  1040,  2022,  7182,  2051,  2003,\n",
       "          2002, 11041,  2010,  3422,   102,     0,     0,     0,     0],\n",
       "        [  101,  1996, 13734,  2787,  2000,  2031,  1037, 19306,  2114,  2037,\n",
       "          3035,   102,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101,  1996,  3696,  2056,  2045,  2001,  2346,  2147,  3805,  2061,\n",
       "          2016,  2787,  2000,  3177,  2039,   102,     0,     0,     0],\n",
       "        [  101,  2006,  1037,  4094,  1997,  2028,  2000,  2702,  1010,  2054,\n",
       "          1005,  1055,  2115,  5440, 14894,  1997,  3609,  1029,   102],\n",
       "        [  101,  3909, 22748,  9728, 25183,  1999,  4559,  2000,  1996, 13523,\n",
       "          4360, 11140,   102,     0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize our input sentences\n",
    "sentences = [\n",
    "    \"it caught him off guard that space smelled of seared steak\",\n",
    "    \"she could not decide between painting her teeth or brushing her nails\",\n",
    "    \"he thought there'd be sufficient time is he hid his watch\",\n",
    "    \"the bees decided to have a mutiny against their queen\",\n",
    "    \"the sign said there was road work ahead so she decided to speed up\",\n",
    "    \"on a scale of one to ten, what's your favorite flavor of color?\",\n",
    "    \"flying stinging insects rebelled in opposition to the matriarch\"\n",
    "]\n",
    "batch = tokenizer(sentences, padding=True, max_length=128, truncation=True, return_tensors=\"pt\")\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67f07d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.6091151 , -0.05289527, -0.735597  , ..., -0.20718901,\n",
       "         0.9009036 , -0.08248363],\n",
       "       [ 0.39508554, -0.67105526, -1.0313998 , ..., -0.5491935 ,\n",
       "        -0.6127097 ,  0.34172556],\n",
       "       [ 0.41667876,  0.01123782,  0.18218265, ..., -0.04224749,\n",
       "        -0.41398963, -0.81505966],\n",
       "       ...,\n",
       "       [ 0.52507514,  0.10277902,  0.3072502 , ...,  0.30447486,\n",
       "        -0.4546693 ,  0.26497468],\n",
       "       [-0.78691447, -0.33936325,  0.02374081, ..., -0.25195748,\n",
       "         0.06752441,  0.20980802],\n",
       "       [-0.8355608 , -0.08190179, -1.2289685 , ..., -0.11544642,\n",
       "         0.06740702,  0.32486174]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feed it through our siamese network's encoder\n",
    "with torch.no_grad():\n",
    "    embeddings = model.encoder(batch[\"input_ids\"].to(device), batch[\"attention_mask\"].to(device))\n",
    "\n",
    "embeddings = embeddings.cpu().numpy()\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26329e3",
   "metadata": {},
   "source": [
    "Given our sentence embedding, we then perform a cosine similarity for finding semantically similar sentences. Notice our trained model was able to capture sentences that have very few matching words but are semantically similar.\n",
    "\n",
    "The comparison is not shown here, but we can compare this with results from out of the box pre-trained models and see that further training these networks with constrastive loss makes day and night differences. i.e. if we were to directly retrieve sentence embeddings by either pooling its last hidden output/layer or extracting first token ([CLS] token)'s embedding, it often times yield rather poor sentence embeddings as mentioned in sentence BERT [[5]](https://arxiv.org/abs/1908.10084)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f87d6c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.18791032,  0.21843803, -0.05063367,  0.6107122 ,  0.07014787,\n",
       "        0.02572602], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embedding = embeddings[-1].reshape(1, -1).repeat(embeddings[:-1].shape[0], axis=0)\n",
    "candidate_embedding = embeddings[:-1]\n",
    "scores = 1 - paired_cosine_distances(input_embedding, candidate_embedding)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95208373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flying stinging insects rebelled in opposition to the matriarch\n",
      "0.1879 | it caught him off guard that space smelled of seared steak\n",
      "0.2184 | she could not decide between painting her teeth or brushing her nails\n",
      "-0.0506 | he thought there'd be sufficient time is he hid his watch\n",
      "0.6107 | the bees decided to have a mutiny against their queen\n",
      "0.0701 | the sign said there was road work ahead so she decided to speed up\n",
      "0.0257 | on a scale of one to ten, what's your favorite flavor of color?\n"
     ]
    }
   ],
   "source": [
    "print(sentences[-1])\n",
    "for i, score in enumerate(scores):\n",
    "    score = round(float(score), 4)\n",
    "    sentence = sentences[i]\n",
    "    print(f\"{score} | {sentence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b1ca77",
   "metadata": {},
   "source": [
    "In this document, we walked through a modern baseline approach for training sentence transformers. Modern in a sense that we are building on top of pre-trained language models instead of training from scratch, baseline meaning there're a lot more we can do to improve these models' performance, we'll take a look at those tricks in future documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb48023f",
   "metadata": {},
   "source": [
    "# Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c81020",
   "metadata": {},
   "source": [
    "- [[1]](https://www.pinecone.io/learn/fine-tune-sentence-transformers-mnr/) Blog: Next-Gen Sentence Embeddings with Multiple Negatives Ranking Loss\n",
    "- [[2]](https://fennel.ai/blog/real-world-recommendation-system/) Blog: Real World Recommendation System  Part 1\n",
    "- [[3]](https://www.sbert.net/examples/applications/retrieve_rerank/README.html) Sentence Transformers Documentation: Retrieve & Re-Rank\n",
    "- [[4]](https://github.com/UKPLab/sentence-transformers/tree/master/examples/training/nli) Github: Sentence Transformers Training Natural Language Inference\n",
    "- [[5]](https://arxiv.org/abs/1908.10084) Paper: Nils Reimers, Iryna Gurevych - Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks - 2019"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
